#######################################################################
##     Historical Credit Card Transaction Data
##      1. 25575 good cards
##      2. 7762 compromized cards
##      3. Each card has 41 histrical transactions
##      4. Timestamp and dollar amount of each transactions
##      5. The most recent transaction of the bad cards is fraudulent
######################################################################
##
##--------------------  Read in raw data sets -----------------------------          
gdc = read.csv("C:\\cpeng\\Research\\JSM2021\\data-prep\\IDXDataset_gdc.csv")
wpc = read.csv("C:\\cpeng\\Research\\JSM2021\\data-prep\\IDXDataset_wpc.csv")
##
##--------------------------------------------------------------------------
##                       Transaction Matrix
##  Each matrix have 41 columns to store 41 transactions for each card
##  The transaction matrix of good card has 25575 rows. The transaction
##  matrix has 7762 rows.
##-------------------------------------------------------------------------
nc.gd0 = dim(gdc)[1]/41
nc.bd = dim(wpc)[1]/41
nr.gd = 41
gdc.amt = gdc$dollar_amt    
gdc.mtrx0 = matrix(gdc.amt, ncol = 41, byrow=TRUE)
wpc.amt = wpc$dollar_amt
wpc.mtrx = matrix(wpc.amt, ncol = 41, byrow=TRUE)
##
##-------------------------------------------------------------------------
##            detect potential unidentified "good cards""
##        More than four consective transactions with identical amounts
##-------------------------------------------------------------------------
##
rep150=NULL
for (i in 1:nc.gd0){
 rep150[i] =  sum(round(gdc.mtrx0[i,])==round(150))
}
del = rep150 < 3
##
gdc.mtrx = gdc.mtrx0[del,] 
nc.gd = dim(gdc.mtrx)[1]
#c(dim(gdc.mtrx0), nc.gd)
##-------------------------------------------------------------------------
##             Define the fraud index using a heuristic PCI
##-------------------------------------------------------------------------
## function for defining PCI
idx.calc = function(alpha, beta, vec){
   a = alpha
   b = beta
   old = vec[-(1:a)]
   new = vec[(1:a)]
   #idx = (b*max(old) + (2-b)*mean(old) - 2*mean(new))/(max(new)-mean(new))
   idx = (b*sd(old) + 2*(mean(old)-mean(new)))/(3*sqrt(var(new)+(mean(old)-mean(new))^2))
   idx
}
##
gd.idx4.15 = NULL
bd.idx4.15 = NULL
for(i in 1:nc.gd) gd.idx4.15[i] = idx.calc(alpha=5, beta = 30, vec=gdc.mtrx[i,])
for(i in 1:nc.bd) bd.idx4.15[i] = idx.calc(alpha=5, beta = 30, vec=wpc.mtrx[i,])
gd50.415 = gd.idx4.15[gd.idx4.15 < 150]    # keep only indexes < 500
bd50.415 = bd.idx4.15[bd.idx4.15 < 150]    # keep only indexes < 500
###########################
##     Libraries
###########################
library(ggplot2)
library(alabama)


##--------------------------------------------------------------------------
##          Visualizing Separability of the fraud index
##   and the shape of the distributions of the two "fraud" indexes 
##--------------------------------------------------------------------------
gd50.415.frm = data.frame(index = gd50.415)
bd50.415.frm = data.frame(index = bd50.415)
gd50.415.frm$status = " good"
bd50.415.frm$status = "fraud"
idx = rbind(gd50.415.frm, bd50.415.frm)
ggplot(idx, aes(index, fill = status)) + geom_density(alpha = 0.2)+
      ggtitle("Smooth Density Curves of Fraud Index") +
      xlab("Fraud Index") + ylab("Density") +
      theme(
         plot.title = element_text(color="darkred", size=14, face="bold.italic", hjust = 0.5, vjust = 0.01),
         axis.title.x = element_text(color="blue", size=10, face="bold"),
         axis.title.y = element_text(color="#993333", size=10, face="bold")
       )
##
##----------------------------------------------------------------------------
##        Determine the initial values of regression coefficients
##  Create a group data and use the prospecive generalized linear model with
##  Cloglog link. The resulting regression coefficients as the initial values
##  to estimate the regression coefficients of the semi-parametric models
##---------------------------------------------------------------------------- 
## 
idxes.gc = as.numeric(names(table(round(gd50.415 ))))
gc.frq = as.vector(table(round(gd50.415 )))
idxes.bc = as.numeric(names(table(round(bd50.415 ))))
bc.frq = as.vector(table(round(bd50.415 )))
gdc.freq=data.frame(good = gc.frq, idx = idxes.gc)
wpc.freq=data.frame(fraud = bc.frq, idx = idxes.bc)
merge.dat = merge(gdc.freq, wpc.freq, by.x = "idx", by.y = "idx", all = TRUE)
merge.dat[is.na(merge.dat)] = 0
merge.dat$total = merge.dat$good + merge.dat$fraud
## merge.dat is the final group data
dat.glmC = glm(cbind(fraud, total) ~ idx, data = merge.dat, family = binomial(link = "cloglog"))
## regression coefficients
a0 = coef(dat.glmC)[1]
b0 = coef(dat.glmC)[2]
##
s0 = (length(bd50.415)/length(gd50.415))   # initial value of theta.
##
##--------------------------------------------------------------------------------------
##            Preparing thr data set for the proposed semiparametric model
##-------------------------------------------------------------------------------------
##
x = gd50.415#[sample(1:length(gd50.415), 1000, replace = F)]
z = bd50.415#[sample(1:length(bd50.415), 200, replace = F)]
t = c(x,z)
### sample sizes and samplin gratio
n0 = length(x)
n1 = length(z)
nn = n0 + n1
##
##------------------------------------------
##  Semiparamteric log-likelihood function
##------------------------------------------
##############################################################
####      Kernel of log-likelihood function
###############################################################
loglik.fun = function(para){
  # parameters
  aa = para[1]
  bb = para[2]
  lbd =para[3]
  ## data vectors
  uz = exp(exp(aa+bb*z)) 
  wz = uz - 1
  ut = exp(exp(aa+bb*t)) 
  wt = ut - 1
  ## score functions
  lglik = sum(log(wz))-sum(log(nn+lbd*(s0*wt-1)))
  lglik
}

##############################################################
####    Newton Method - for MLE of regression coefficients
###############################################################
## 1. score functions
score.fun = function(para){
  # parameters
  aa = para[1]
  bb = para[2]
  lbd =para[3]
  ## data vectors
  uz = exp(exp(aa+bb*z)) 
  rz = uz*exp(aa+bb*z)
  wz = uz - 1
  ##
  ut = exp(exp(aa+bb*t)) 
  rt = ut*exp(aa+bb*t)
  wt = ut - 1
  ## score functions
  fa = sum(rz/wz) - sum((lbd*s0*rt)/(nn+lbd*(s0*wt-1)))
  fb = sum(z*rz/wz) - sum((t*lbd*s0*rt)/(nn+lbd*(s0*wt-1)))
  flbd = - sum((s0*wt-1)/(nn+lbd*(s0*wt-1)))
  ff = c(fa, fb, flbd)
  ff
}
##
###########################################
##     3. initial value of lambda
###########################################
##
lambda.ini = function(para){
  aa = para[1]
  bb = para[2]
  ##
  ut = exp(exp(aa+bb*t)) 
  wt = ut - 1
  ##
  lambda = function(y) sum(1/(nn+y*(s0*wt-1)))-1
  lbd = uniroot(lambda, c(-1, 1), tol = 0.0001)$root
  lbd
 }
lbd0 = lambda.ini(c(a0, b0))
##
result=optim(c(a0,b0,lbd0), loglik.fun, score.fun, method="BFGS", hessian=TRUE, 
               control=list(maxit=1000, fnscale=-1))
#varcov = -solve(result$hessian)  # variance-covariance matrix of the MLE
mle = result$par

##---------------------------------------------------------------------------------
##      Fitted "Fraud" Probability Using Fraud Index With the Proposed Model
##--------------------------------------------------------------------------------
gd.fraud.prob = 1 - exp(-exp(mle[1]+mle[2]*gd50.415))
bd.fraud.prob = 1 - exp(-exp(mle[1]+mle[2]*bd50.415))
##
cutt = 0.8
c(sum(gd.fraud.prob>cutt), sum(bd.fraud.prob>cutt))
sum(bd.fraud.prob>cutt)/(sum(gd.fraud.prob>cutt) + sum(bd.fraud.prob>cutt))
sum(gd.fraud.prob>cutt)/(sum(gd.fraud.prob>cutt) + sum(bd.fraud.prob>cutt))

### plot
gd.prob.frm = data.frame(fraud.prob = gd.fraud.prob)
bd.prob.frm = data.frame(fraud.prob = bd.fraud.prob)
gd.prob.frm$status = " good"
bd.prob.frm$status = "fraud"
fraud.prob.all = rbind(gd.prob.frm, bd.prob.frm)
write.csv(fraud.prob.all,"C:\\cpeng\\Research\\JSM2021\\data-prep\\fraudprob.csv", row.names = FALSE)
## for by probabilities
#srt.fraud.prob = fraud.prob.all[order(fraud.prob),]
ggplot(fraud.prob.all, aes(fraud.prob, fill = status)) + 
      geom_density(alpha = 0.2) +
      ggtitle("Estimated Smooth Density Curves of Fraud Probabilities") +
      xlab("Fraud Probability") + ylab("Density") +
      theme(
         plot.title = element_text(color="darkred", size=14, face="bold.italic", hjust = 0.5, vjust = 0.01),
         axis.title.x = element_text(color="blue", size=10, face="bold"),
         axis.title.y = element_text(color="#993333", size=10, face="bold")
       )

#############################################################
###   standard normal, logistic and extreme value densities
#############################################################
par(mfrow=c(1,2))
col.code = c("red", "blue", "cyan")
xx=seq(-8,8, length=500)
norm = (1/sqrt(2*pi))*exp(-xx^2/2)
logi = exp(-xx)/(1+exp(-xx))^2
extr = exp(xx-exp(xx))
plot(xx, norm, type = "l", lty =1, lwd = 2, col = 'red', xlab="", ylab="",
     main = "Comparison of density curves")
lines(xx, logi, lty = 1, lwd = 2, col = "blue")
lines(xx, extr, lty = 1, lwd = 2, col = "cyan")
legend("topleft", c("Normal", "Logistic", "Extreme"), lty=rep(1,3), lwd=rep(2,3), col = col.code, cex = 0.8, bty = "n")
### CDF
cdf.norm = pnorm(xx)
cdf.logi=1/(1+exp(-xx))
cdf.extr = 1-exp(-exp(xx))
plot(xx, cdf.norm, type = "l", lty =1, lwd = 2, col = 'red', xlab="", ylab="",
     main = "Comparison of cumulative distribution curves")
lines(xx, cdf.logi, lty = 1, lwd = 2, col = "blue")
lines(xx, cdf.extr, lty = 1, lwd = 2, col = "cyan")
legend("topleft", c("Normal", "Logistic", "Extreme"), lty=rep(1,3), lwd=rep(2,3), col = col.code, cex = 0.8, bty = "n")

########################################################################
####       Fraud Index Distribution (Kernel Density Estimation)
#########################################################################        
par(mfrow=c(1,2))
### Fraud index through an automatic feature engineering
plot(density(gd50.415)$x, density(gd50.415)$y, type="l", lwd = 2, lty =1, col="purple",
             xlab = "fraud Index", ylab = "density", main = "Fraud Index Distributions")
lines(density(bd50.415)$x, density(bd50.415)$y, type="l", lwd = 2, lty =1, col="navy")
legend("topright", c("Authentic Cards", "Compromised Cards"), lty=rep(1,2), lwd = rep(2,2),
        col=c("purple", "navy"), cex = 0.8, bty = "n")
abline(h = 0, col = "red")

#### 
idx.cut = seq(50, 200, length=200)
gd.idx.cnt = NULL
bd.idx.cnt = NULL
for (i in 1:200){
  gd.idx.cnt[i] = sum(gd50.415 > idx.cut[i])
  bd.idx.cnt[i] = sum(bd50.415 > idx.cut[i])
}
alert.idx.cnt = gd.idx.cnt + bd.idx.cnt
FPR.alert = gd.idx.cnt / alert.idx.cnt
TNR.alert = bd.idx.cnt / alert.idx.cnt
##
plot(idx.cut, FPR.alert, type = "l", xlab = "Fraud Index", ylab = "False Positive Rate",
       main = "Various FPR/FNR Based on Alerts", col = "blue", lty =1)
lines(idx.cut, TNR.alert, col="darkred", lty = 1)
## plot ROC
plot(1-TNR.alert, FPR.alert, type = "l",col="blue", lty = 1, lwd = 2)
abline(0,1, lty=2, col = "red")





#########################################################
par(mfrow=c(1,2))
plot(density(gd.fraud.prob)$x, density(gd.fraud.prob)$y, type="l", lwd = 2, lty =1, col="purple",
             xlab = "fraud Probabity", ylab = "density", main = "Cloglog Fraud Probability Distributions")
lines(density(bd.fraud.prob)$x, density(bd.fraud.prob)$y, type="l", lwd = 2, lty =1, col="navy")
legend("topright", c("Authentic Cards", "Compromised Cards"), lty=rep(1,2), lwd = rep(2,2),
        col=c("purple", "navy"), cex = 0.8, bty = "n")
abline(h = 0, col = "red")
###

prob.cut = seq(0, 1, length=200)
gd.prob.cnt = NULL
bd.prob.cnt = NULL
for (i in 1:200){
  gd.prob.cnt[i] = sum(gd.fraud.prob > prob.cut[i])
  bd.prob.cnt[i] = sum(bd.fraud.prob > prob.cut[i])
}
alert.prob.cnt = gd.prob.cnt + bd.prob.cnt
FPR.prob = gd.prob.cnt / alert.prob.cnt
TNR.prob = bd.prob.cnt / alert.prob.cnt
plot(prob.cut, FPR.prob, type = "l", xlab = "Fraud Index", ylab = "False Positive Rate",
       main = "Various FPR/FNR Based on Cloglog Model", col = "blue", lty =1)

lines(prob.cut, TNR.prob, col="darkred", lty = 1)
## plot ROC
plot(1-TNR.prob, FPR.prob, type = "l",col="blue", lty = 1, lwd = 2)
abline(0,1, lty=2, col = "red")































##---------------------------------------------------------------------------------
##      Fitted "Fraud" Probability Using Fraud Index With the Proposed Model
##--------------------------------------------------------------------------------
gd.fraud.prob = 1 - exp(-exp(-2.0917291771+0.0456415116*gd50.415))
bd.fraud.prob = 1 - exp(-exp(-2.0917291771+0.0456415116*bd50.415))
##
gd.fraud.prob0 = gd.fraud.prob[gd.fraud.prob<0.01]
bd.fraud.prob0 = bd.fraud.prob[bd.fraud.prob<0.01]
###
cutt = 0.006
c(sum(gd.fraud.prob>cutt), sum(bd.fraud.prob>cutt))

##sum(bd.fraud.prob0>cutt)/(sum(gd.fraud.prob0>cutt) + sum(bd.fraud.prob0>cutt))


##---------------------------------------------------------------------------
##           Visualization: Distribution of fraud probabilities
##---------------------------------------------------------------------------
##
library(ggplot2)















